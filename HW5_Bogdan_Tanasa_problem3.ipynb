{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98ce8b-a89f-4ec0-bd4d-b8a02d996225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb89e56-0da5-4e8a-9861-c98df88974b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.1: Using the Huggingfaceâ€™s Transformer library and the â€˜sentiment-analysisâ€™ pipeline, \n",
    "#              analyze the sentiments of the following sentences.\n",
    "# I like NLP course.\n",
    "# I hate when my computer crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6fdf0b-3b1b-48c0-acae-cbff3d92ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:32:42.798071: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-08 21:32:42.806467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731130362.817201    7287 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731130362.820362    7287 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 21:32:42.831334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7fb0dd-5591-443d-8334-fddb8eca56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\",  model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                                             device = -1,  framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8266e0f-ba1d-4462-aa56-12fba226b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'I like NLP course.' :: Sentiment: {'label': 'POSITIVE', 'score': 0.9993118047714233}\n",
      "Sentence: 'I hate when my computer crashes.' :: Sentiment: {'label': 'NEGATIVE', 'score': 0.9994106292724609}\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I like NLP course.\", \"I hate when my computer crashes.\"]\n",
    "sentiment_results = classifier(sentences)\n",
    "\n",
    "for sentence, result in zip(sentences, sentiment_results):\n",
    "    print(f\"Sentence: '{sentence}' :: Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6ac2c-10de-4c82-9aed-ecd27eac0e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc245a2-2243-4155-aee5-6c1320e91c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.2 : Using the Huggingfaceâ€™s Transformer library and â€˜zero-shot-classificationâ€™ pipeline,\n",
    "#               classify the following sentence in one of the three given classification categories.\n",
    "# Text: Los Angeles Clippers is a good basketball team\n",
    "# Given Classification categories = sports, politics, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f9064e-7a7e-4532-8a07-168302264034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "text = \"Los Angeles Clippers is a good basketball team\"\n",
    "labels = [\"sports\", \"politics\", \"education\"]\n",
    "\n",
    "classification_results = classifier(text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387e8f1b-1973-461f-a355-ec02a7b50a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'Los Angeles Clippers is a good basketball team'\n",
      "Labels: '['sports', 'politics', 'education']'\n",
      "Analysis Results:\n",
      "  sports: 0.9974\n",
      "  education: 0.0016\n",
      "  politics: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: '{text}'\")\n",
    "print(f\"Labels: '{labels}'\")\n",
    "print(\"Analysis Results:\")\n",
    "for label, score in zip(classification_results[\"labels\"], classification_results[\"scores\"]):\n",
    "    print(f\"  {label}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1c0fb-0d81-435f-a11d-046ec6e10b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a10a4c6-e145-48fb-8f24-4dacf8ed8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.3: Using the Huggingfaceâ€™s Transformer library and â€˜text-generationâ€™ pipeline, complete the following sentence.\n",
    "# In this month, the stock market will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc59683d-6112-4f6c-8d7f-222ca14d79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier3 = pipeline(\"text-generation\", \n",
    "                          model=\"gpt2\", \n",
    "                          device = -1,  \n",
    "                          framework=\"pt\")\n",
    "\n",
    "sentence = \"In this month, the stock market will\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20eeabeb-4018-48b7-9651-ccb578430921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'In this month, the stock market will'\n",
      " Newly Generated Text: In this month, the stock market will close down 2.2%, with investors looking for opportunities in futures, investment banking, and other sectors where stocks are most traded.\n",
      "\n",
      "Futures trades are particularly important for traders of companies where some of\n"
     ]
    }
   ],
   "source": [
    "generated_sentence = classifier3(sentence, max_length=50, num_return_sequences=1)\n",
    "\n",
    "print(f\"Prompt: '{sentence}'\\n Newly Generated Text: {generated_sentence[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c06ba-dca2-4177-a108-5d35685481fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f9080d7-1d7b-482c-ab37-7c1feb05d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.4: Using the Huggingfaceâ€™s Transformer library and â€˜fill-maskâ€™ pipeline, fill in the blanks.\n",
    "# Math course will teach you about <mask> topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa365280-4e7c-435b-92ed-d09545ed78d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible text:\n",
      "math course will teach you about various topics (score: 0.1314)\n",
      "math course will teach you about math topics (score: 0.0918)\n",
      "math course will teach you about many topics (score: 0.0883)\n",
      "math course will teach you about all topics (score: 0.0741)\n",
      "math course will teach you about different topics (score: 0.0579)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fillings = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "masked_sentence = \"Math course will teach you about [MASK] topics\"\n",
    "fillings_results = fillings(masked_sentence, top_k=5)  \n",
    "\n",
    "print(\"Possible text:\")\n",
    "for result in fillings_results:\n",
    "    print(f\"{result['sequence']} (score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bca59-b650-4afd-a10b-09896cbf132d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60083dff-4729-48aa-8256-0ca972fa8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.5: Using the Huggingfaceâ€™s Transformer library and â€˜nerâ€™ (Name Entity Recognition) pipeline, identify name, \n",
    "# organization, and place.\n",
    "# Tim Cook is the CEO of Apple located in San Jose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a48929-4366-438e-baae-b1c7848c2a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/bogdan/miniconda3/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Components:\n",
      "Tim Cook: PER (score: 0.9997)\n",
      "Apple: ORG (score: 0.9987)\n",
      "San Jose: LOC (score: 0.9984)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_model = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
    "\n",
    "sentence = \"Tim Cook is the CEO of Apple located in San Jose.\"\n",
    "ner_model_results = ner_model(sentence)\n",
    "\n",
    "print(\"Identified Components:\")\n",
    "for component in ner_model_results:\n",
    "    print(f\"{component['word']}: {component['entity_group']} (score: {component['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e50e9-7172-407f-a883-52348bae3965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d937c33-ce63-406a-810b-c648aa4a6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.6: Using the Huggingfaceâ€™s Transformer library and â€˜question-answeringâ€™ pipeline, let the system find the answer \n",
    "# to the following question in the given context.\n",
    "# Question: In which state Los Angeles located\n",
    "# Context: Los Angeles is in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfae7b93-1bcc-4d32-9dbe-4ab8cbfe5e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 'In which state is Los Angeles located?'\n",
      "Answer: California\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "question = \"In which state is Los Angeles located?\"\n",
    "context = \"Los Angeles is in California.\"\n",
    "\n",
    "resultsqa = qa(question=question, context=context)\n",
    "\n",
    "print(f\"Question: '{question}'\")\n",
    "print(f\"Answer: {resultsqa['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cc39a-19dc-49c0-852e-48deaf35b426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbc5676-9ca1-43c5-bace-442975998672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.7: Using the Huggingfaceâ€™s Transformer library and â€˜summarizeâ€™ pipeline, summarize the following text.\n",
    "# Text:\n",
    "# Australia was celebrated for its initial response to the Covid-19 pandemic,\n",
    "# and for getting its economy more or less back on track long ago. But with\n",
    "# that security has come complacency, particularly in the federal government,\n",
    "# which failed to secure enough vaccine doses to prevent the regular \"circuit\n",
    "# breaker\" lockdowns that come every time a handful of cases emerge, or even\n",
    "# the longer restrictions that Sydney is experiencing now. Australia's\n",
    "# borders, controlled by strict quarantine measures, have been all but shut\n",
    "# for more than a year. Now Australians, who basked in their early successes,\n",
    "# are wondering how much longer this can go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b761cb3c-6b2d-45a9-99b9-1230fd5858f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Australia was celebrated for its initial response to the Covid-19 pandemic. But with that security has come complacency, particularly in the federal government. The government failed to secure enough vaccine doses to prevent the regular \"circuit\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizing = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = \"\"\"\n",
    "Australia was celebrated for its initial response to the Covid-19 pandemic,\n",
    "and for getting its economy more or less back on track long ago. But with\n",
    "that security has come complacency, particularly in the federal government,\n",
    "which failed to secure enough vaccine doses to prevent the regular \"circuit\n",
    "breaker\" lockdowns that come every time a handful of cases emerge, or even\n",
    "the longer restrictions that Sydney is experiencing now. Australia's\n",
    "borders, controlled by strict quarantine measures, have been all but shut\n",
    "for more than a year. Now Australians, who basked in their early successes,\n",
    "are wondering how much longer this can go on.\n",
    "\"\"\"\n",
    "\n",
    "summary_results = summarizing(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(\"Summary:\")\n",
    "print(summary_results[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d2d3b-d36b-44f4-8d37-998ffcfd94ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
